"""
æ›´æ–°ç‰ˆï¼šé€šç”¨ç€è¦½å™¨åª’é«”æŠ“å–å™¨ï¼ˆåœ–ç‰‡/å½±ç‰‡ï¼‰
-------------------------------------------------
å®Œæ•´ç‰ˆæœ¬ï¼ŒåŒ…å«ï¼š
- URL è¼¸å…¥ã€åœ–ç‰‡/å½±ç‰‡æ ¼å¼é¸æ“‡
- Playwrightï¼ˆå¯é¸ï¼‰èˆ‡é€²éšç€è¦½å™¨é¸é …æŠ˜ç–Š
- æƒææ™‚ç½®ä¸­å¤§å‹ GIF æç¤º
- ç¸®åœ–é è¦½ã€å¤§å°ï¼ˆä»¥ KB æµ®é»æ•¸ï¼‰å³æ™‚ç¯©é¸æ‹‰éœ¸ã€æ’åºæŒ‰éˆ•
- å…¨é¸/å–æ¶ˆå…¨é¸ã€ä¼°ç®—ç¸½å¤§å°ï¼ˆé€æ­¥ HEADï¼‰
- ä¸‹è¼‰ä½ç½®è‡ªè¨‚ï¼†è¨˜æ†¶ã€è·¨å¹³å°å•Ÿå‹•å™¨ï¼ˆWindows/macOSï¼‰
"""

import os
import sys
import json
import time
import pathlib
from dataclasses import dataclass
import hashlib
from typing import List, Tuple, Dict, Optional
import platform

# --- Windows asyncio äº‹ä»¶è¿´åœˆä¿®æ­£ï¼šPlaywright éœ€è¦ Proactor loop æ”¯æ´ subprocess ---
import asyncio, sys
if sys.platform.startswith("win"):
    try:
        asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())
    except Exception:
        pass


import pandas as pd
import requests
import streamlit as st
from bs4 import BeautifulSoup
from urllib.parse import urljoin, urlparse
from concurrent.futures import ThreadPoolExecutor, as_completed

APP_TITLE = "é€šç”¨ç€è¦½å™¨åª’é«”æŠ“å–å™¨ï¼ˆåœ–ç‰‡/å½±ç‰‡ï¼‰"
CONFIG_PATH = os.path.join(os.path.expanduser("~"), ".web_media_scraper_gui.json")
DEFAULT_HEADERS = {
    "User-Agent": (
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 "
        "(KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36"
    ),
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8",
    "Accept-Language": "zh-TW,zh;q=0.9,en;q=0.8",
    "Cache-Control": "no-cache",
    "Pragma": "no-cache",
}
REQUEST_TIMEOUT = 20
MAX_THREADS = 16
CHUNK = 1024 * 128
IMAGE_EXT_DEFAULT = ["jpg", "jpeg", "png", "webp", "gif", "bmp", "svg"]
VIDEO_EXT_DEFAULT = ["mp4", "webm", "mov", "m4v", "avi", "mkv"]

@dataclass
class MediaItem:
    url: str
    kind: str  # "image" or "video"
    filename: str
    size: Optional[int] = None  # bytes
    content_type: str = ""

def fetch_html_playwright(...):
    # ç¢ºä¿åœ¨ Windows ä¸‹æ˜¯ Proactor loopï¼ˆé¿å… NotImplementedErrorï¼‰
    if sys.platform.startswith("win"):
        try:
            asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())
        except Exception:
            pass
    ...

def load_config() -> Dict:
    if os.path.exists(CONFIG_PATH):
        try:
            with open(CONFIG_PATH, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception:
            return {}
    return {}

def save_config(cfg: Dict) -> None:
    try:
        with open(CONFIG_PATH, "w", encoding="utf-8") as f:
            json.dump(cfg, f, ensure_ascii=False, indent=2)
    except Exception:
        pass

def human_kb(n: Optional[int]) -> str:
    if n is None or n < 0:
        return "â€”"
    kb = n / 1024
    if kb < 1024:
        return f"{kb:.1f} KB"
    mb = kb / 1024
    if mb < 1024:
        return f"{mb:.2f} MB"
    gb = mb / 1024
    return f"{gb:.2f} GB"

# ---- Playwright æ¸²æŸ“ï¼ˆé¸ç”¨ï¼‰----

def fetch_html_requests(url: str, timeout_sec: int = 20) -> str:
    """ä»¥ requests å–å¾— HTMLï¼Œå¸¶å¸¸è¦‹ç€è¦½å™¨æ¨™é ­ï¼Œä¸¦å…è¨± 302 è¿½è¹¤ã€‚"""
    r = requests.get(url, headers=DEFAULT_HEADERS, timeout=timeout_sec, allow_redirects=True)
    r.raise_for_status()
    return r.text

def fetch_html_playwright(url: str, channel: Optional[str] = None, exe_path: Optional[str] = None, timeout_sec: int = 40, do_scroll: bool = True) -> str:
    try:
        from playwright.sync_api import sync_playwright
    except Exception as e:
        raise RuntimeError("è«‹å…ˆå®‰è£ Playwrightï¼špip install playwright ä¸¦åŸ·è¡Œ 'playwright install'") from e

    with sync_playwright() as p:
        launch_kwargs = {"headless": True}
        if channel:
            launch_kwargs["channel"] = channel
        browser = p.chromium.launch(**launch_kwargs)
        try:
            context = browser.new_context()
            page = context.new_page()
            page.set_default_timeout(timeout_sec * 1000)
            page.goto(url, wait_until="networkidle")
            if do_scroll:
                for _ in range(6):
                    page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
                    page.wait_for_timeout(400)
            html = page.content()
            # å­˜ Referer/Cookie ä¾›ä¹‹å¾Œ HEAD/ä¸‹è¼‰å¸¶å…¥
            try:
                cookies = context.cookies()
                cookie_header = "; ".join([f"{c['name']}={c['value']}" for c in cookies])
                st.session_state.playwright_cookies = cookie_header
                st.session_state.page_referer = url
            except Exception:
                pass
            return html
        finally:
            browser.close()

# ---- å·¥å…·å‡½å¼ ----

def normalize_url(base_url: str, src: Optional[str]) -> Optional[str]:
    if not src:
        return None
    try:
        u = urljoin(base_url, src)
        p = urlparse(u)
        return p._replace(fragment="").geturl()
    except Exception:
        return None

def head_content_length(url: str) -> Tuple[Optional[int], str]:
    try:
        headers = DEFAULT_HEADERS.copy()
        if st.session_state.get("page_referer"):
            headers["Referer"] = st.session_state.get("page_referer")
        if st.session_state.get("playwright_cookies"):
            headers["Cookie"] = st.session_state.get("playwright_cookies")
        r = requests.head(url, headers=headers, timeout=REQUEST_TIMEOUT, allow_redirects=True)
        if r.status_code >= 400 or "Content-Length" not in r.headers:
            r = requests.get(url, headers=headers, timeout=REQUEST_TIMEOUT, stream=True)
        size = None
        if "Content-Length" in r.headers:
            try:
                size = int(r.headers["Content-Length"])
            except Exception:
                size = None
        ctype = r.headers.get("Content-Type", "")
        return size, ctype
    except Exception:
        return None, ""

def enrich_sizes(items: List[MediaItem]) -> None:
    with ThreadPoolExecutor(max_workers=MAX_THREADS) as ex:
        fut_map = {ex.submit(head_content_length, it.url): it for it in items}
        for fut in as_completed(fut_map):
            it = fut_map[fut]
            try:
                size, ctype = fut.result()
                it.size = size
                it.content_type = ctype
            except Exception:
                it.size = None
                it.content_type = ""

def download_one(it: MediaItem, folder: str) -> Tuple[str, bool, Optional[int]]:
    try:
        headers = DEFAULT_HEADERS.copy()
        if st.session_state.get("page_referer"):
            headers["Referer"] = st.session_state.get("page_referer")
        if st.session_state.get("playwright_cookies"):
            headers["Cookie"] = st.session_state.get("playwright_cookies")
        resp = requests.get(it.url, headers=headers, timeout=REQUEST_TIMEOUT, stream=True)
        resp.raise_for_status()
        fname = pathlib.Path(it.filename).name or f"file_{int(time.time())}"
        fpath = os.path.join(folder, fname)
        total_written = 0
        with open(fpath, "wb") as f:
            for chunk in resp.iter_content(chunk_size=CHUNK):
                if not chunk:
                    continue
                f.write(chunk)
                total_written += len(chunk)
        return fpath, True, total_written
    except Exception:
        return it.url, False, None

# ---- ä¸»ç¨‹å¼ ----

def main():
    st.set_page_config(page_title=APP_TITLE, layout="wide")
    cfg = load_config()

    # Session state åˆå§‹åŒ–
    for k, v in {
        "media_items": [],              # List[MediaItem]
        "items_df": None,               # DataFrame æª¢è¦–
        "scanned": False,
        "size_unit": "KB",
        "spinner_url": "https://media.tenor.com/On7kvXhzml4AAAAj/loading-gif.gif",
        "sort_desc": True,
        "size_range_kb": None,
        "playwright_cookies": "",
        "page_referer": "",
    }.items():
        if k not in st.session_state:
            st.session_state[k] = v

    # Sidebar
    with st.sidebar:
        st.markdown(f"#### {APP_TITLE}")
        url = st.text_input("ğŸŒ", placeholder="è¼¸å…¥ç¶²å€")
        img_exts = st.multiselect("åœ–ç‰‡æ ¼å¼", IMAGE_EXT_DEFAULT, default=IMAGE_EXT_DEFAULT)
        vid_exts = st.multiselect("å½±ç‰‡æ ¼å¼", VIDEO_EXT_DEFAULT, default=["mp4", "webm", "mov"])

        use_js = st.checkbox(
            "ä½¿ç”¨ç„¡é ­ç€è¦½å™¨æ¸²æŸ“ (Playwright)", value=False,
            help="éœ€è¦ JS/SPA çš„é é¢å»ºè­°é–‹å•Ÿï¼ˆéœ€ pip install playwright ä¸¦ playwright installï¼‰",
        )
        with st.expander("é€²éšç€è¦½å™¨é¸é …ï¼ˆå°‘ç”¨æ™‚å¯æ”¶èµ·ï¼‰", expanded=False):
            channel = st.selectbox("ç€è¦½å™¨ channelï¼ˆé¸å¡«ï¼‰", ["(auto)", "chrome", "msedge"], index=0)
            if channel == "(auto)":
                channel = None
            exe_path = st.text_input("ç€è¦½å™¨ EXE è·¯å¾‘ï¼ˆé¸å¡«ï¼‰", value="")

        spinner_input = st.text_input("æƒæå‹•ç•« GIF é€£çµ", value=st.session_state.spinner_url)
        if spinner_input:
            st.session_state.spinner_url = spinner_input.strip()

        download_dir = st.text_input(
            "ä¸‹è¼‰è³‡æ–™å¤¾",
            value=cfg.get("last_download_dir", os.path.join(os.path.expanduser("~"), "Downloads")),
        )
        remember = st.checkbox("è¨˜ä½æ­¤ä¸‹è¼‰ä½ç½®", value=True)
        if st.button("å„²å­˜è¨­å®š"):
            if remember:
                cfg["last_download_dir"] = download_dir
            save_config(cfg)
            st.success("è¨­å®šå·²ä¿å­˜")

        st.markdown("---")
        st.markdown("**å¿«é€Ÿå•Ÿå‹•ï¼ˆWindows / macOSï¼‰**")
        app_dir_default = pathlib.Path(__file__).resolve().parent.as_posix()
        custom_app_dir = st.text_input("App è³‡æ–™å¤¾ (é è¨­ç‚ºæ­¤æª”æ¡ˆä½ç½®)", app_dir_default)
        if st.button("åœ¨æ¡Œé¢å»ºç«‹å•Ÿå‹•å™¨ (Win/macOS)"):
            try:
                desktop = os.path.join(os.path.expanduser("~"), "Desktop")
                os.makedirs(desktop, exist_ok=True)
                if platform.system() == "Windows":
                    launcher_path = os.path.join(desktop, "é€šç”¨ç€è¦½å™¨åª’é«”æŠ“å–å™¨.bat")
                    script = f"""@echo off
chcp 65001 >nul
cd /d "{custom_app_dir}"
if exist .venv\\Scripts\\activate.bat (call .venv\\Scripts\\activate.bat)
where streamlit >nul 2>nul
if %errorlevel%==0 (
  start "" cmd /c "streamlit run app.py & pause"
) else (
  start "" cmd /c "python -m streamlit run app.py & pause"
)
"""
                    with open(launcher_path, "w", encoding="utf-8") as f:
                        f.write(script)
                    st.success(f"å·²å»ºç«‹ï¼š{launcher_path}")
                else:  # macOS
                    launcher_path = os.path.join(desktop, "é€šç”¨ç€è¦½å™¨åª’é«”æŠ“å–å™¨.command")
                    script = f"""#!/bin/bash
cd "{custom_app_dir}"
if [ -d .venv ]; then
  source .venv/bin/activate
fi
if command -v streamlit >/dev/null 2>&1; then
  streamlit run app.py
else
  python3 -m streamlit run app.py
fi
read -n 1 -s -r -p "Press any key to close..."
"""
                    with open(launcher_path, "w") as f:
                        f.write(script)
                    os.chmod(launcher_path, 0o755)
                    st.success(f"å·²å»ºç«‹ï¼š{launcher_path}")
            except Exception as e:
                st.error(f"å»ºç«‹å•Ÿå‹•å™¨å¤±æ•—ï¼š{e}")

    # ---- æƒææŒ‰éˆ• & æµç¨‹ ----
    scan_btn = st.button("ğŸ” æƒæåª’é«”")
    center_holder = st.empty()

    if scan_btn:
        if not url:
            st.warning("è«‹è¼¸å…¥ç¶²å€")
        else:
            with center_holder.container():
                c1, c2, c3 = st.columns([1, 2, 1])
                with c2:
                    st.image(st.session_state.spinner_url, caption="æ­£åœ¨æƒæï¼Œè«‹ç¨å€™â€¦", width=400)
            try:
                if use_js:
                    html = fetch_html_playwright(url, channel=channel, exe_path=exe_path or None, timeout_sec=40)
                else:
                    try:
                        html = fetch_html_requests(url, timeout_sec=REQUEST_TIMEOUT)
                    except requests.HTTPError as e:
                        status = getattr(e.response, 'status_code', None)
                        if status in (401, 403):
                            st.warning(f"ç›®æ¨™ç¶²ç«™æ‹’çµ•ç›´é€£ï¼ˆHTTP {status}ï¼‰ã€‚å·²è‡ªå‹•æ”¹ç”¨ç„¡é ­ç€è¦½å™¨é‡è©¦â€¦")
                            html = fetch_html_playwright(url, channel=channel, exe_path=exe_path or None, timeout_sec=40)
                        else:
                            raise
                soup = BeautifulSoup(html, "html.parser")

                found: Dict[str, MediaItem] = {}
                def add_item(u: Optional[str], kind: str):
                    if not u or u in found:
                        return
                    path = urlparse(u).path.lower()
                    if kind == "image":
                        if ("." in path and any(path.endswith("."+ext) for ext in IMAGE_EXT_DEFAULT)) or ("." not in path):
                            filename = pathlib.Path(urlparse(u).path).name or f"image_{hashlib.md5(u.encode()).hexdigest()[:8]}.jpg"
                            found[u] = MediaItem(url=u, kind="image", filename=filename)
                    else:
                        if ("." in path and any(path.endswith("."+ext) for ext in VIDEO_EXT_DEFAULT)) or ("." not in path):
                            filename = pathlib.Path(urlparse(u).path).name or f"video_{hashlib.md5(u.encode()).hexdigest()[:8]}.mp4"
                            found[u] = MediaItem(url=u, kind="video", filename=filename)

                # <img> + srcset
                for img in soup.find_all("img"):
                    add_item(normalize_url(url, img.get("src")), "image")
                    if img.get("srcset"):
                        parts = [s.strip().split(" ")[0] for s in img.get("srcset").split(",") if s.strip()]
                        for p in parts:
                            add_item(normalize_url(url, p), "image")
                # <video> + <source>
                for v in soup.find_all("video"):
                    add_item(normalize_url(url, v.get("src")), "video")
                    for s in v.find_all("source"):
                        add_item(normalize_url(url, s.get("src")), "video")
                # <a href>
                for a in soup.find_all("a"):
                    u = normalize_url(url, a.get("href"))
                    if not u:
                        continue
                    path = urlparse(u).path.lower()
                    if any(path.endswith("."+ext) for ext in IMAGE_EXT_DEFAULT):
                        add_item(u, "image")
                    if any(path.endswith("."+ext) for ext in VIDEO_EXT_DEFAULT):
                        add_item(u, "video")

                items = list(found.values())
                total = len(items)
                if total:
                    prog = st.progress(0)
                    stat = st.empty()
                    batch = 8
                    for i in range(0, total, batch):
                        enrich_sizes(items[i:i+batch])
                        done = min(total, i+batch)
                        total_known = sum((it.size or 0) for it in items)
                        stat.info(f"å³å°‡æŠ“å–ï¼š{done}/{total}ï¼Œä¼°è¨ˆç¸½å¤§å°ï¼š{human_kb(total_known)}")
                        prog.progress(int(done/total*100))

                st.session_state.media_items = items
                st.session_state.scanned = True
            finally:
                center_holder.empty()

    # ---- çµæœé¡¯ç¤º ----
    if st.session_state.scanned and st.session_state.media_items:
        items = st.session_state.media_items
        df = pd.DataFrame([
            {
                "ID": i,
                "é¸å–": True,
                "é¡å‹": it.kind,
                "ç¸®åœ–": (it.url if it.kind == "image" else ""),
                "æª”å": it.filename,
                "å¤§å°_bytes": ((it.size/1024.0) if (it.size is not None) else -1.0),  # å–®ä½ï¼šKBï¼ˆæµ®é»ï¼‰
                "Content-Type": it.content_type,
                "URL": it.url,
            }
            for i, it in enumerate(items)
        ])
        st.session_state.items_df = df

        sizes_known = [float(s) for s in df["å¤§å°_bytes"].tolist() if s is not None and s >= 0]
        kb_min = float(min(sizes_known)) if sizes_known else 0.0
        kb_max = float(max(sizes_known)) if sizes_known else 0.0
        unit = "MB" if kb_max >= 1024 else "KB"

        if st.session_state.size_range_kb is None:
            st.session_state.size_range_kb = (kb_min, kb_max)

        if unit == "MB":
            lo_disp = st.session_state.size_range_kb[0] / 1024.0
            hi_disp = st.session_state.size_range_kb[1] / 1024.0
            lo_disp, hi_disp = st.slider(
                "é¸å–å¤§å°ç¯„åœ",
                min_value=float(kb_min/1024.0),
                max_value=float(max(kb_max/1024.0, kb_min/1024.0 + 0.1)),
                value=(float(lo_disp), float(hi_disp)),
                step=0.1,
                format="%.1f MB",
            )
            lo_kb, hi_kb = lo_disp * 1024.0, hi_disp * 1024.0
        else:
            lo_kb, hi_kb = st.slider(
                "é¸å–å¤§å°ç¯„åœ",
                min_value=float(kb_min),
                max_value=float(max(kb_max, kb_min + 0.1)),
                value=(float(st.session_state.size_range_kb[0]), float(st.session_state.size_range_kb[1])),
                step=0.1,
                format="%.1f KB",
            )
        st.session_state.size_range_kb = (lo_kb, hi_kb)

        def _fmt_kb(v: float) -> str:
            return f"{v:.1f} KB" if v < 1024 else f"{v/1024:.1f} MB"
        st.caption(f"ç›®å‰ç¯„åœï¼š{_fmt_kb(lo_kb)} ï½ {_fmt_kb(hi_kb)}")

        df_view = df.copy()
        in_range = (df_view["å¤§å°_bytes"] >= lo_kb) & (df_view["å¤§å°_bytes"] <= hi_kb)
        df_view.loc[:, "é¸å–"] = in_range

        if st.button(f"æŒ‰å¤§å°æ’åºï¼ˆ{'å¤§â†’å°' if st.session_state.sort_desc else 'å°â†’å¤§'}ï¼‰"):
            st.session_state.sort_desc = not st.session_state.sort_desc
        df_view = df_view.sort_values(by="å¤§å°_bytes", ascending=not st.session_state.sort_desc)

        col_all, col_none = st.columns(2)
        with col_all:
            if st.button("å…¨é¸"):
                df_view.loc[:, "é¸å–"] = True
        with col_none:
            if st.button("å–æ¶ˆå…¨é¸"):
                df_view.loc[:, "é¸å–"] = False

        edited = st.data_editor(
            df_view[["é¸å–", "é¡å‹", "ç¸®åœ–", "æª”å", "å¤§å°_bytes", "Content-Type", "URL", "ID"]],
            use_container_width=True,
            hide_index=True,
            column_config={
                "é¸å–": st.column_config.CheckboxColumn("é¸å–"),
                "ç¸®åœ–": st.column_config.ImageColumn("ç¸®åœ–", width=220),
                "å¤§å°_bytes": st.column_config.NumberColumn("å¤§å°(KB)", format="%.1f"),
                "URL": st.column_config.TextColumn("ğŸ”—", width="small"),
                "ID": st.column_config.NumberColumn("ID", format="%d", help="å…§éƒ¨ç´¢å¼•"),
            },
            num_rows="dynamic",
        )

        sel_mask = edited["é¸å–"] == True
        selected_ids = edited.loc[sel_mask, "ID"].astype(int).tolist()
        sel_items = [items[i] for i in selected_ids]
        total_sel = len(sel_items)
        total_bytes = sum((it.size or 0) for it in sel_items)
        st.info(f"å³å°‡ä¸‹è¼‰ï¼š{total_sel} å€‹æª”æ¡ˆï¼Œç¸½å¤§å° {human_kb(total_bytes)}")

        if st.button("â¬‡ï¸ ä¸‹è¼‰å·²å‹¾é¸é …ç›®"):
            folder = download_dir.strip() or os.path.join(os.path.expanduser("~"), "Downloads")
            os.makedirs(folder, exist_ok=True)
            if remember:
                cfg["last_download_dir"] = folder
                save_config(cfg)
            prog = st.progress(0)
            for idx, it in enumerate(sel_items, start=1):
                path_or_url, ok, bytes_written = download_one(it, folder)
                if ok:
                    st.write(f"âœ… {it.filename} ({human_kb(bytes_written)})")
                else:
                    st.write(f"âš ï¸ ä¸‹è¼‰å¤±æ•—ï¼š{path_or_url}")
                prog.progress(int(idx/len(sel_items)*100))

if __name__ == "__main__":
    main()
